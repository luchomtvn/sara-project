{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "import os\n",
    "import re\n",
    "from pyscripts.settings import output_dir, wosis_dir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leemos el archivo descargado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 841 entries, 0 to 840\n",
      "Data columns (total 15 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   gml_id             841 non-null    object \n",
      " 1   profile_id         841 non-null    int64  \n",
      " 2   profile_layer_id   841 non-null    int64  \n",
      " 3   country_name       841 non-null    object \n",
      " 4   upper_depth        841 non-null    int64  \n",
      " 5   lower_depth        841 non-null    int64  \n",
      " 6   layer_name         789 non-null    object \n",
      " 7   litter             827 non-null    float64\n",
      " 8   orgc_value         841 non-null    object \n",
      " 9   orgc_value_avg     841 non-null    float64\n",
      " 10  orgc_method        841 non-null    object \n",
      " 11  orgc_date          841 non-null    object \n",
      " 12  orgc_dataset_id    841 non-null    object \n",
      " 13  orgc_profile_code  841 non-null    object \n",
      " 14  orgc_licence       841 non-null    object \n",
      "dtypes: float64(2), int64(4), object(9)\n",
      "memory usage: 98.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_orgc = pd.read_csv(wosis_dir + \"wosis_latest_orgc_Argentina.csv\")\n",
    "df_orgc.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1: Obtener los promedios ponderados de un material para los perfiles de un pais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculamos el carbono concentrado de un perfil para los primeros 30cm\n",
    "\n",
    "la columna orgc_value_avg tiene los valores de carbono para una capa. Solo se deben considerar los primeros 30cm asi que si una capa sobrepasa ese limite se debe tomar un parcial. Para calcular el carbono de esa capa se hace un promedio ponderado de los parciales de cada capa. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vamos a tomar los primeros tres perfiles que aparecen en el dataset como ejemplo, y solo vamos a tener en cuenta los primeros 30 cm. Esto se puede hacer usando las columnas upper_depth y lower_depth, que nos indican los limites superiores e inferiores de la capa en cuestion. \n",
    "\n",
    "Por ejemplo, del perfil 63821, vamos a tomar las primeras dos capas y solo 7cm de la tercer capa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>profile_id</th>\n",
       "      <th>profile_layer_id</th>\n",
       "      <th>upper_depth</th>\n",
       "      <th>lower_depth</th>\n",
       "      <th>orgc_value_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63821</td>\n",
       "      <td>53190</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>9.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63821</td>\n",
       "      <td>53191</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63821</td>\n",
       "      <td>53192</td>\n",
       "      <td>23</td>\n",
       "      <td>45</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63821</td>\n",
       "      <td>53193</td>\n",
       "      <td>45</td>\n",
       "      <td>100</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63822</td>\n",
       "      <td>53194</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>63823</td>\n",
       "      <td>53195</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>63823</td>\n",
       "      <td>53196</td>\n",
       "      <td>17</td>\n",
       "      <td>34</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>63823</td>\n",
       "      <td>53197</td>\n",
       "      <td>34</td>\n",
       "      <td>58</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>63823</td>\n",
       "      <td>53198</td>\n",
       "      <td>58</td>\n",
       "      <td>100</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   profile_id  profile_layer_id  upper_depth  lower_depth  orgc_value_avg\n",
       "0       63821             53190            0            7             9.7\n",
       "1       63821             53191            7           23            11.9\n",
       "2       63821             53192           23           45            14.0\n",
       "3       63821             53193           45          100             6.8\n",
       "4       63822             53194            0           25             5.0\n",
       "5       63823             53195            0           17             2.0\n",
       "6       63823             53196           17           34             2.0\n",
       "7       63823             53197           34           58             3.0\n",
       "8       63823             53198           58          100             4.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nos quedamos con las columnas relevantes\n",
    "cols1 = ['profile_id', 'profile_layer_id', 'upper_depth', 'lower_depth', 'orgc_value_avg']\n",
    "dff = df_orgc[0:9][cols1]\n",
    "dff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculo de promedios ponderados de concentracion de carbono organico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### funcion de agrupamiento\n",
    "\n",
    "https://pandas.pydata.org/docs/user_guide/groupby.html#\n",
    "\n",
    "tiene q ser una funcion a nivel de fila. \n",
    "\n",
    "toda la informacion que necesito esta en upper y lower, ahi tengo si me pase de 30cm y cuanto mide la layer. Con eso puedo calcular el ponderado en una columna nueva y despues cuando hago el groupby lo puedo dividir por el largo total."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>profile_id</th>\n",
       "      <th>orgc_pond_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63821</td>\n",
       "      <td>11.876667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63822</td>\n",
       "      <td>4.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63823</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   profile_id  orgc_pond_val\n",
       "0       63821      11.876667\n",
       "1       63822       4.166667\n",
       "2       63823       2.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def poderate_avg(profiles, property, limit):\n",
    "    col = property + '_value_avg'\n",
    "    if(profiles['upper_depth'] > limit):\n",
    "        return 0.0 \n",
    "\n",
    "    if(profiles['lower_depth'] > limit):\n",
    "        partial_depth = limit - profiles['upper_depth']\n",
    "        return (partial_depth * profiles[col])/limit\n",
    "    else:\n",
    "        return ((profiles['lower_depth'] - profiles['upper_depth']) * profiles[col])/limit\n",
    "\n",
    "\n",
    "dff['orgc_pond_val'] = dff.apply(poderate_avg, args=('orgc', 30), axis=1)\n",
    "dff[['profile_id', 'orgc_pond_val']].groupby('profile_id').sum().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para que funcione bien este codigo es importante que no se cambien los nombres de las columnas. Ni de los archivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya obtuvimos los promedios ponderados para cada perfil. El analisis para el resto de las propiedades del perfil (clay, bulk density) es similar. \n",
    "\n",
    "Lo que resta ahora es aplicar esta metodologia para todas las propiedades que hagan falta y luego mergear los datasets. Luego de mergear, van a quedar espacios en nulo para aquellos perfiles que no posean al menos una de las propiedades usadas. En cada caso se vera si se puede conseguir la informacion de otro lugar. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traemos el resto de los datasets para hacerles el mismo calculo y luego mergearlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bulk = pd.read_csv( wosis_dir + \"wosis_latest_bdfi33_Argentina.csv\")\n",
    "df_clay = pd.read_csv( wosis_dir + \"wosis_latest_clay_Argentina.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 55 entries, 0 to 54\n",
      "Data columns (total 15 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   gml_id               55 non-null     object \n",
      " 1   profile_id           55 non-null     int64  \n",
      " 2   profile_layer_id     55 non-null     int64  \n",
      " 3   country_name         55 non-null     object \n",
      " 4   upper_depth          55 non-null     int64  \n",
      " 5   lower_depth          55 non-null     int64  \n",
      " 6   layer_name           52 non-null     object \n",
      " 7   litter               55 non-null     int64  \n",
      " 8   bdfi33_value         55 non-null     object \n",
      " 9   bdfi33_value_avg     55 non-null     float64\n",
      " 10  bdfi33_method        55 non-null     object \n",
      " 11  bdfi33_date          55 non-null     object \n",
      " 12  bdfi33_dataset_id    55 non-null     object \n",
      " 13  bdfi33_profile_code  55 non-null     object \n",
      " 14  bdfi33_licence       55 non-null     object \n",
      "dtypes: float64(1), int64(5), object(9)\n",
      "memory usage: 6.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_bulk.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 857 entries, 0 to 856\n",
      "Data columns (total 15 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   gml_id             857 non-null    object \n",
      " 1   profile_id         857 non-null    int64  \n",
      " 2   profile_layer_id   857 non-null    int64  \n",
      " 3   country_name       857 non-null    object \n",
      " 4   upper_depth        857 non-null    int64  \n",
      " 5   lower_depth        857 non-null    int64  \n",
      " 6   layer_name         820 non-null    object \n",
      " 7   litter             857 non-null    int64  \n",
      " 8   clay_value         857 non-null    object \n",
      " 9   clay_value_avg     857 non-null    float64\n",
      " 10  clay_method        857 non-null    object \n",
      " 11  clay_date          857 non-null    object \n",
      " 12  clay_dataset_id    857 non-null    object \n",
      " 13  clay_profile_code  857 non-null    object \n",
      " 14  clay_licence       857 non-null    object \n",
      "dtypes: float64(1), int64(5), object(9)\n",
      "memory usage: 100.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_clay.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos la funcion 'ponderate' sobre los tres datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_profile_summary(df, property):\n",
    "    prop_pond_col = property + '_pond_val'\n",
    "    df[prop_pond_col] = df.apply(poderate_avg, args=(property, 30), axis=1)\n",
    "    return df[['profile_id', prop_pond_col]].groupby('profile_id').sum().reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "luego los unimos en uno solo para obtener la informacion resumida de la concentracion de cada propiedad en cada perfil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>profile_id</th>\n",
       "      <th>orgc_pond_val</th>\n",
       "      <th>clay_pond_val</th>\n",
       "      <th>bdfi33_pond_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63821</td>\n",
       "      <td>11.876667</td>\n",
       "      <td>45.533333</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63822</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63823</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>16.133333</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63824</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>31.666667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63825</td>\n",
       "      <td>16.556667</td>\n",
       "      <td>10.533333</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>71870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>71919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>71950</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.166667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>176590</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.583333</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>176591</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.706667</td>\n",
       "      <td>0.816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>249 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     profile_id  orgc_pond_val  clay_pond_val  bdfi33_pond_val\n",
       "0         63821      11.876667      45.533333              NaN\n",
       "1         63822       4.166667      12.500000              NaN\n",
       "2         63823       2.000000      16.133333              NaN\n",
       "3         63824      17.500000      31.666667              NaN\n",
       "4         63825      16.556667      10.533333              NaN\n",
       "..          ...            ...            ...              ...\n",
       "244       71870            NaN       6.300000              NaN\n",
       "245       71919            NaN       3.000000              NaN\n",
       "246       71950            NaN       8.166667              NaN\n",
       "247      176590            NaN      19.583333              NaN\n",
       "248      176591            NaN      20.706667            0.816\n",
       "\n",
       "[249 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = [df_orgc, df_clay, df_bulk]\n",
    "properties = ['orgc', 'clay', 'bdfi33']\n",
    "grouped = []\n",
    "\n",
    "for df, property in zip(dfs, properties):\n",
    "    grouped.append(get_profile_summary(df, property))\n",
    "profille_summary = reduce(lambda l, r: pd.merge(l, r, on='profile_id', how='outer'), grouped)\n",
    "profille_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 249 entries, 0 to 248\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   profile_id       249 non-null    int64  \n",
      " 1   orgc_pond_val    213 non-null    float64\n",
      " 2   clay_pond_val    227 non-null    float64\n",
      " 3   bdfi33_pond_val  12 non-null     float64\n",
      "dtypes: float64(3), int64(1)\n",
      "memory usage: 9.7 KB\n"
     ]
    }
   ],
   "source": [
    "profille_summary.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La mayoria de los valores en bdfi33 estan en nulo porque solo hay 12 perfiles con informacion de bulk density wn wosis. *Por lo que esta informacion necesariamente tiene que obtenerse de otra fuente*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2: Obtenemos todos los archivos para todos los paises y repetimos el procedimiento haciendo un resumen por perfil para todos los paises de interes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero se deben obtener todos los archivos que se tengan. Asumimos que se encuentran en el directorio wosis_latest dentro de este repositorio y que respetan el siguiente formato de nombre:\n",
    "\n",
    "*wosis_latest_property_country.format*\n",
    "\n",
    "donde:\n",
    "- property: clay, orgc, bdfi33, etc\n",
    "- country: Argentina, Uruguay, etc (comienzan con mayuscula)\n",
    "- format: gpkg, csv, etc (shp no funciona aun)\n",
    "\n",
    "ejemplo:\n",
    "\n",
    "*wosis_latest_clay_Argentina.csv*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En cuanto a los archivos, podemos asumir que existen o crearlos dentro del script. De todas maneras, para leerlos, se escanea el directorio en busca de los archivos para evitar errores de file not found. No hay nada que procesar si no hay archivos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscamos los archivos existentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para buscar los archivos, tenemos que tener definido un formato. De otra forma traeriamos informacion repetida (repetida?? o cada formato trae algo distinto?? **CONFIRMAR ESTO**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wosis_latest_clay_Argentina.csv\n",
      "wosis_latest_orgc_Uruguay.csv\n",
      "wosis_latest_bdfi33_Uruguay.csv\n",
      "wosis_latest_clay_Chile.csv\n",
      "wosis_latest_clay_Uruguay.csv\n",
      "wosis_latest_bdfi33_Argentina.csv\n",
      "wosis_latest_orgc_Argentina.csv\n",
      "wosis_latest_bdfi33_Chile.csv\n",
      "wosis_latest_orgc_Chile.csv\n"
     ]
    }
   ],
   "source": [
    "## we compose a regular expression to help us search for the files we want to process\n",
    "\n",
    "format = 'csv' # format is fixed\n",
    "countries = '|'.join(['Argentina', 'Uruguay', 'Chile'])\n",
    "properties = '|'.join(['clay', 'orgc', 'bdfi33'])\n",
    "\n",
    "files_re = re.compile(f'wosis_latest_({properties})_({countries}).{format}')\n",
    "files = []\n",
    "\n",
    "with os.scandir(wosis_dir) as entries:\n",
    "    for entry in entries:\n",
    "        if re.search(files_re, entry.name):\n",
    "            print(entry.name)\n",
    "            files.append(entry.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por cada archivo encontrado, se obtiene el dataset y se procesa. Al final se guarda todo en un summary, como en la parte 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para incluir al pais en el proceso, hay que modificar la funcion get_profile_summary. Una asumicion importante es que no va a haber un perfil con el mismo ID en otro pais, por lo que no es necesario unir por pais y por perfil cuando se hace el merge. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# primero vamos a redefinir la funcion de summary para que incluya al pais\n",
    "def get_profile_summary(df, property):\n",
    "    prop_pond_col = property + '_pond_val'\n",
    "    df[prop_pond_col] = df.apply(poderate_avg, args=(property, 30), axis=1)\n",
    "    return df[['profile_id', 'country_name', prop_pond_col]].groupby(['profile_id', 'country_name']).sum().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No hay nada por lo que unir en datasets de distintos paises porque no hay ningun profile que se comparta, sin embargo en el merge hay que unir por pais para que pandas no cree una columna nueva para ese campo. \n",
    "\n",
    "\n",
    "Lo que tiene mas sentido entonces, es mergear los datasets de cada pais para obtener los resumenes de cada perfil y despues stackear los datasets para obtener uno grande con todos los paises. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>profile_id</th>\n",
       "      <th>country_name</th>\n",
       "      <th>clay_pond_val</th>\n",
       "      <th>bdfi33_pond_val</th>\n",
       "      <th>orgc_pond_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63821</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>45.533333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.876667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63822</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63823</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>16.133333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63824</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>31.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63825</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>10.533333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.556667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10786</th>\n",
       "      <td>732831</td>\n",
       "      <td>Chile</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>127.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10787</th>\n",
       "      <td>732832</td>\n",
       "      <td>Chile</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10788</th>\n",
       "      <td>732833</td>\n",
       "      <td>Chile</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10789</th>\n",
       "      <td>732834</td>\n",
       "      <td>Chile</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10790</th>\n",
       "      <td>732835</td>\n",
       "      <td>Chile</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11176 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       profile_id country_name  clay_pond_val  bdfi33_pond_val  orgc_pond_val\n",
       "0           63821    Argentina      45.533333              NaN      11.876667\n",
       "1           63822    Argentina      12.500000              NaN       4.166667\n",
       "2           63823    Argentina      16.133333              NaN       2.000000\n",
       "3           63824    Argentina      31.666667              NaN      17.500000\n",
       "4           63825    Argentina      10.533333              NaN      16.556667\n",
       "...           ...          ...            ...              ...            ...\n",
       "10786      732831        Chile            NaN              NaN     127.310000\n",
       "10787      732832        Chile            NaN              NaN       2.000000\n",
       "10788      732833        Chile            NaN              NaN       1.000000\n",
       "10789      732834        Chile            NaN              NaN       4.000000\n",
       "10790      732835        Chile            NaN              NaN       2.000000\n",
       "\n",
       "[11176 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group = []\n",
    "countries = {}\n",
    "for file in files:\n",
    "    if(format == 'csv'):\n",
    "        df = pd.read_csv(wosis_dir + file)\n",
    "        property = file.split(\"_\")[-2]\n",
    "        country = file.split(\"_\")[-1].split(\".\")[0]\n",
    "        if country not in countries.keys():\n",
    "            countries[country] = []\n",
    "        countries[country].append(get_profile_summary(df, property))\n",
    "\n",
    "reduced_countries = {}\n",
    "for key in countries:\n",
    "    reduced_countries[key] = reduce(lambda l, r: pd.merge(l, r, on=['profile_id', 'country_name'], how='outer'), countries[key])\n",
    "        \n",
    "profille_summary = pd.concat(reduced_countries.values())\n",
    "profille_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>profile_id</th>\n",
       "      <th>country_name</th>\n",
       "      <th>clay_pond_val</th>\n",
       "      <th>bdfi33_pond_val</th>\n",
       "      <th>orgc_pond_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>68646</td>\n",
       "      <td>Uruguay</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   profile_id country_name  clay_pond_val  bdfi33_pond_val  orgc_pond_val\n",
       "7       68646      Uruguay       7.666667              NaN           10.2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profille_summary[profille_summary['profile_id'] == 68646]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "profille_summary.to_csv(output_dir + 'profile_summary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('neoland')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "13aa3a90a5e641235fea1601ecd5c89f84592ee55de82aab0f64a36e64690c8c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
